<chapter xml:id="fake-news"  xmlns:xi="http://www.w3.org/2001/XInclude">
	<title>Fake News</title>
	<introduction xml:id="fake-news-introduction">
		<title>Introduction</title>
		<p>
			<em>This module was authored by <xref ref="ccarpenter"/> and <xref ref="jmakansi"/>.</em>
		</p>
	</introduction>
	<section xml:id="fake-news-objectives">
		<title>Objectives</title>
		<ol>
			<li>
				For students to understand how to avoid misinformation using the five C’s.
			</li>
			<li>
				For students to understand how avoid misinformation stemming from misleading graphs.
			</li>
		</ol>
	</section>
	<section xml:id="fake-news-understanding-the-issue">
		<title>Understanding the Issue</title>
		<p>
			In 1475, in the city of Trent, in what is now Italy, a two-year-old boy named Simon was brutally murdered. The body was found in the cellar of a Jewish family. A rumor quickly spread around town that the Jewish community had murdered the child and used his blood for their religious ceremonies. The local authorities of Trent rounded up Jewish members of the community, tortured them into false confessions, and executed some of them. Representatives from the Roman Catholic Church investigated and found no evidence of the involvement of any of the town’s Jewish community, but the local authorities convicted the community of the crime. Kristeller describes the rise of anti-semitic writing of poems and articles written about the incident that were printed in multiple languages in Europe <xref ref="fake-news-biblio-simon-of-trent"/>. This spread of Simon’s story reminds us that “fake news” and the use of it to oppress minorities has a long history. 
		</p>
		<p>
			The scholars Lazer et al. defined fake news as “fabricated information that mimics news media content in form but not in organizational process or intent” (p. 1094) <xref ref="fake-news-biblio-science-of-fake-news"/>. It’s information that looks like real news, but is not. These scholars go on to note how easily such misinformation spreads online where anyone can post information and it can potentially reach millions by being shared on social media platforms like Facebook or Twitter.
		</p>
		<p>
			When the misinformation is about whether or not a particular celebrity is romantically involved with another celebrity, the potential for harm is not high. But attempts at social justice can be thwarted by the spread of false or misleading information. One issue concerns which problems a given society faces. Is crime going up or down? If it is going up, then it is easier to convince people to divert public funds towards policing. If it is going down, perhaps such money could be spent on rehabilitation of criminals. A related question is whether or not police in a given area disproportionately kill people of color. If a problem does not appear to exist, it is difficult to build political will towards solving it. The same difficulty occurs with global climate change. Is the global temperature average increasing? Are humans causing it? Will it cause problems? If the public believes that the answer to any of these questions is “no” then the public will not support climate change abatement efforts.
		</p>
		<p>
			The other side of this coin concerns solutions. Even if people have an accurate view of what the problems are, false information can make it harder to build support for workable solutions. For example, what are the effects of programs designed to reduce poverty? If misleading information is publicized that seems to show particular programs fail, then the public will not support those programs and the poorest members of our community will suffer more. Similarly, if proposed methods of reducing carbon emissions are inaccurately portrayed as failures, then such methods will not be adopted. 
		</p>
	</section>
	<section xml:id="fake-news-cui-bono">
		<title>Cui Bono – Who Benefits?</title>
		<p>
			If we cannot get accurate information, then people cannot solve problems together. If people cannot agree on what the problems are, how widespread they are, and how effective various solutions are, they will not be able to work on making life better for everyone. If we as a people do not make any progress, then the people who stand to gain from the current system continue to benefit. When no one can agree on how to solve problems, then the people who benefit from the existence of the problems will continue to receive those benefits.  
		</p>
	</section>
	<section xml:id="fake-news-big-problem">
		<title>Big Problem</title>
		<assemblage>
			<p>
				Essentially, to identify and solve problems in a democracy, the public must have accurate information. In this chapter we hope to show you some tools for thinking about information you find online so that you will not fall prey to fake news. How can we identify fake news when we see it?
			</p>
		</assemblage>
	</section>
	<section xml:id="fake-news-error-analysis">
		<title>Error Analysis</title>
		<subsection xml:id="fake-news-error-analysis-introduction">
			<title>Introduction to Error Analysis</title>
			<p>
				Fake news is one type of “misinformation” or disinformation.” However, much of the “news” can be simply misleading. Some people or news outlets convey misleading quantitative information unconsciously; some do it deliberately. Researchers often present numerical results, and conclusions based on those results, without also putting forth enough effort to calculate and report the uncertainties and inaccuracies in those results. Perhaps more insidious, many professionals construct quantitative information to serve a pre-disposition, a political goal, or a business objective. What is an individual reader or consumer of this information to do?
			</p>
			<p>
				One thing you can do is apply something called uncertainty and error analysis. This can be done informally as you read through a piece, but error analysis is also a rigorous mathematical discipline all to itself.
			</p>
			<p>
				Let’s first consider a real-world situation in which uncertainty proved to be catastrophic. In 1985, the NASA spaceship Challenger, with the first civilian passenger, exploded shortly after takeoff. A post-mortem, or after-event, analysis was conducted and the NASA team struggled to explain what happened to the public, until Richard Feynman, a well-known physicist, dropped a rubber O-ring (something used to seal off an area) in a beaker of ice water and showed how the rubber became inflexible. It turned out that the failure of this O-ring was the root cause of the explosion.
			</p>
			<p>
				The ability of that O-ring to hold up during the near-freezing temperatures during launch was an uncertainty which had propagated through to the launch event. It may have been the neglect of the NASA engineering team to think through all of the components and how they might fare under adverse conditions. It may have been that the launch team made a fatal assumption “in the moment” that the O-ring would remain stable enough. Whatever the deeper explanation, uncertainty surrounding that O-ring’s behavior at those temperatures led to a catastrophe. Uncertainty analysis, which is also more broadly categorized as risk assessment, is designed to flag such issues, especially for enormously complex engineering systems like a spaceship.
			</p>
			<p>
				Now let’s turn to a error analysis as a discipline. Unless it is a highly theoretical treatment, most quantitative and numerical analysis begins with measurements of some kind. Temperature is a measurement. So is an answer to a question in an opinion poll. All measurements have error. Unfortunately, that error propagates through the analysis and the event the analysis supports, and can even get magnified.
			</p>
			<p>
				Here is a simple example of how error gets magnified that also illustrates rigor: Suppose I want to calculate the volume of a large cubic concrete tank. Well, that’s pretty easy from a math perspective. The volume of a cube is the length of one side cubed, or <m>V = L^3</m>, where V is volume and L is length. So, I just have to measure the length of a side. I take a tape measure and measure the side. Let’s say I measure it at 36 inches. There is an inherent inaccuracy to the tape measure; let’s say it is <m>/pm 1/8</m> in. Oh, and did I make sure that the tape measure was completely straight and rigid from one side to the other? Maybe not. Maybe there’s a 1-inch error because of that. Or maybe I stretched my arms so far, I really only “eyeballed” the length. 
			</p>
			<p>
				Let’s assume there’s a total of 2 in. of error in my measurement.  I calculate the volume as <m>36 x 36 x 36 = 46656 in^3</m>. Now, to report the error in this numerical result, I also have to concede that the length could be between 34 and 38. So the volume based on those two numbers are 39,304 and 54,872. Suddenly, that’s a pretty big spread!
			</p>
			<p>
				Whether the error is significant or not depends on what you do with the number. The error could have a financial impact if you are buying the materials to construct such a concrete tank. The error could have little or no impact if you just need an estimate for something else.
			</p>
			<p>
				The critical point is that the error in the original measurement has now been propagated and magnified in the final numerical result.
			</p>
			<p>
				Now suppose I want to calculate the volume of the cylindrical fiberglass water reclamation tank I am staring at in my backyard as I write this. The equation for the volume of a cylindrical object is area of the base x height = volume and area of a circle is <m>\pi r^2</m> = Area. In this case, I have to make two measurements, height and diameter (diameter is twice the radius represented as r in the equation). I can measure the height with a tape measure, although that tank has been sitting there for 15 years so I’m not sure how much of bottom is under the gravel surrounding it. I can “back-calculate” the radius by measuring the circumference with the tape measure. 
			</p>
			<p>
				You probably can see where this is going. Two measurements, each with their own sources of error propagated and magnified into the final numerical result.
			</p>
			<p>
				Now consider some numerical results with grave consequences. The forecasts for global climate change and its consequences involve some of the most sophisticated measurements and computer modeling humanity has ever devised. While it might seem overwhelming to consider the error in each of the measurements and how they are propagated, you can take comfort in the fact that thousands of researchers around the world are arriving at similar conclusions. Only a small percentage of scientists deny that human-induced climate change is advancing dangerously.
			</p>
			<p>
				But here’s how politics come into play. Climate policy makers, and climate deniers, use a parameter called the “social cost of carbon” to “monetize” the effects of climate change. This is a very complex analysis. But realize that the Environmental Protection Agency in the Obama administration used a figure around $50/ton carbon, while Trump administration officials revised the analysis and came up with a figure of around $7/ton. How could such an important figure be so different? The answer is that the analysis involves several key assumptions. Change the assumptions and you can drastically change the result.
			</p>
			<p>
				Many news reports containing quantitative results will give, at best, a cursory view of the error in those results. Journalists don’t have an infinite amount of column inches to devote to the story. Researchers often are limited by the number of pages they can publish for a journal article. But realize that every one of these numerical results has sources of error, often significant or even huge, and many of them will not be exposed. It is up to the reader to think through them.
			</p>
			<p>
				So, one root cause of misinformation or misleading information is the error in the original measurements. Sadly, much of what we are presented as “information” is based on measurements which are not physical measurements, as in the examples above, but are data arrived at in various ways. If I want to understand public sentiment about gun violence, for example, I can commission an opinion poll. There are rigorous procedures for taking polls and then doing statistical analysis on the results. But statistical error is very different from, say, the biases inherent in the person formulating the questions for the poll. 
			</p>
			<p>
				Sadly, much news we consume is not even intended to pursue an “objective truth” (even as a direction), but instead is constructed to support a position. Consulting firms, government departments, policy shops, NGOs, and others spend or raise millions of dollars to generate reports which are consumed by elected officials, and breathtakingly reported by journalists, but that often amount to a string of assumptions wrapped around cherry-picked data presented in dazzling, colorful graphs (see next section).
			</p>
			<p>
				Our message here is that fake news often has quantitative and numerical components to it, but you don’t need to know math or be a “quant type” to think a bit more deeply about those results. You do need to be a healthy skeptic, however, and simple “qualitative tools,” like error analysis, will help you. 
			</p>
			<p>
				In closing this section, it is important not to throw your hands up and say “all information is tainted, there is no truth.” “Facts” and “truth” are asymptotic, which means simply that we can get closer and closer even if there is always some doubt or “error.” Error and uncertainty, however, are compensated for as you consider the following “path” towards real knowledge and away from fake news:
			</p>
			<p>
				Coincidence or randomness – one thing that happens (“I was assaulted in the park so this must be a high crime neighborhood”) or two things that happen around the same time (“my friend was assaulted in the same park the same week”) may constitute coincidence or randomness but not real information. Something similar can be said for a researcher or policy expert who reports results from an analysis or experiment that has not been repeated or validated by others.
			</p>
			<ul>
				<li>
					<term>Correlation</term> – an association between two things (gun sales and violent crime, e.g., in a specific region) may show a weak or strong statistical correlation, or a significant association, which would have to be corroborated to constitute information you can rely on.
				</li>
				<li>
					<term>Causation</term> – something caused by another thing (human industrial and consumption activity and global average temperature rises, as opposed to natural causes of those temperature rises) is a much higher bar to scale. This requires many independent and repeatable studies, perhaps coming at the problem from different directions.
				</li>
				<li>
					<term>Convergence</term> – Specialists and experts collaborate and review each other’s work and begin to converge on a common “theory of the case” or explanation for why something is occurring.
				</li>
				<li>
					<term>Consensus</term> – experts can gather in a room and nod their heads in agreement, but so what? Consensus among decision makers and their constituencies are then necessary for any action to be taken based on the information and knowledge.
				</li>
			</ul>
			<p>
				Error and uncertainty in the information are progressively and incrementally reduced to low or insignificant levels as the analysis proceeds along the path of the “five C’s.”
			</p>
			<p>
				Any one of these steps alone is insufficient. After all, the townspeople of Trent, Italy, achieved consensus around the fake news of the murder of Simon by the Jews in their community, and acted on the fake news. They did not withhold judgment until the “analysis” came out.
			</p>
		</subsection>
		<subsection xml:id="fake-news-error-analysis-error-propogation">
			<title>Error Propogation</title>
			<p>
				Let's look at an example of how errors can propogate in a calculation, and how that can produce very different results in a calculation.
			</p>
			<p>
				In May 2024, the Congressional Budget Office (CBO), a non-partisan group which analyzes the cost of potential legislation, posted an analysis of a tax plan presented by the Republican Party <xref ref="fake-news-biblio-congressional-budget-office"/>.  The analysis said that the tax plan, which called for tax cuts on wealthier taxpayers and corporations, would cost $4.6 trillion (<m>10^12</m>) dollars over the next 10 years.
			</p>
			<p>
				The mathematics that the CBO uses to make these calculations are pretty far beyond where we are in this class, but we'll focus on something else very interesting in this report.  The CBO previously had estimated that the tax plan would cost $3.5 trillion dollars over 10 years - an estimate that was off by $1.1 trillion dollars - which is a huge amount.  How could their estimate have been off by so much? And more importantly, which of these estimates is correct?  A group which is in favor of the tax plan might want to use the smaller number to make the point that the tax cuts would not cost the government as much, while a group which is opposed could use the higher number to make the argument that their opposition is justified.
			</p>
			<p>
				When we make estimates of something, there will always be some expected error - if it were perfect, it wouldn't be an estimate! For example, imagine I asked you to estimate how much money you would spend on food this week - the chances of you getting the answer exactly correct are pretty small.  When we make mathematical estimates, mathematicians usually prefer to use a range of values - for example, a mathematician might say "I'll spend $50-$150 on food this week." This is much more likely to be a correct statement than saying "I will spend exactly $100 on food this week," since the correct value only needs to be in the interval!
			</p>
			<p>
				If we give our estimate as an interval, half of the width of that interval is called the <term>margin of error</term>.  In our example above, we would say that our estimate of food costs is $100, with a margin of error of <m>\frac{150-50}{2} = 50</m>.  We can also write the interval as <m>100\pm 50</m>.
			</p>
			<p>
				When we use estimates like this, the errors from multiple estimates can combine, a process called <term>error propogation</term>.  For example, we know that <m>10*20 = 200</m>.  However, assume that we had an estimate of <m>a = 10\pm 5</m> times an estimate of <m>b = 20\pm 3</m>.  Our values for <m>a</m> range from 5 to 15, and our values for <m>b</m> range from 17 to 23.  That means our product <m>a*b</m> could be as small as <m>5*17 = 85</m> and as large as <m>15*23 = 345</m>.  When we multiply an estimate with a margin of error of <m>\pm 5</m> times an estimate with a margin of error of <m>\pm 3</m>, we get a margin of error of <m>\frac{345-85}{2} = 130</m>!  This error propogation explains why we can get such huge variation in estimates, especially when our numbers are large - even when our initial estimates are very good.
			</p>
			<p>
				We'll look at a very simplified example of this problem to illustrate how we can get such large errors in an example like this.   
			</p>
			<activity xml:id="fake-news-error-propogation-basics">
				<introduction>
					<p>
						Let's imagine a situation where everyone pays 10% tax on their income. A city wants to estimate the tax that their citizens will pay.  They estimate that there are between 2.5 and 2.7 million people in the city, and that the average taxable income of those people is between $47,000 and $49,000.
					</p>
				</introduction>
				<task>
					<statement>
						<p>
							Use the low estimates of the population and average income to calculate the lower end of the estimated tax collected.
						</p>
					</statement>
					<solution>
						<p>
							We multiply the low end of the estimate for the population (2,500,000) times the low end of the estimate for the income ($47,000) times 10% (0.1).
							<me>2,500,000*47,000*0.1 = 1.175*10^{10}</me>
							Our low estimate for the tax collected is 11.75 billion dollars.
						</p>
					</solution>
				</task>
				<task>
					<statement>
						<p>
							Use the high estimates of the population and average income to calculate the higher end of the estimated tax collected.
						</p>
					</statement>
					<solution>
						<p>
							We multiply the high end of the estimate for the population (2,700,000) times the high end of the estimate for the income ($49,000) times 10% (0.1).
							<me>2,700,000*49,000*0.1 = 1.323*10^{10}</me>
							The high estimate for the tax collected is 13.23 billion dollars.
						</p>
					</solution>
				</task>		
			</activity>
			<p>
				With error propogation, the more quantities we combine in our estimate, the greater the margin of error in our final calculation.
			</p>
			<activity xml:id="fake-news-error-propogation-three-quantities">
				<statement>
					Consider a city now where, rather than everyone paying 10% tax, people pay between 8% and 12%.  Repeat the calculations from <xref ref="fake-news-error-propogation-basics"/> with this variable tax rate.  What are the low and high ends for your estimates now?
				</statement>
				<solution>
					<p>
						The low estimate is
						<me>2,500,000*47,000*0.08 = 9.4*10^9</me>
						and the high estimate is
						<me>2,700,000*49,000*0.12 = 1.5876*10^{10}</me>
					</p>
					<p>
						The estimated tax is now between $9.4 billion and $15.8 billion.
					</p>
				</solution>
			</activity>
		</subsection>
	</section>
	<section xml:id="fake-news-misleading-graphs">
		<title>Misleading Graphs</title>
		<p>
			Graphs can be a great way to display information in a way that helps people understand the relationships among numbers. For example, <xref ref="fake-news-misleading-graphs-figure-climate"/> shows temperature changes over the last two thousand years. There is, of course, a lot of variation over time. Then, when we hit the Industrial Revolution, when carbon emissions increased substantially, and the line starts trending upwards very quickly.
		</p>
		<figure xml:id="fake-news-misleading-graphs-figure-climate">
			<image source="fake-news/images/climate-change.png">
				Graph of mean temperature anomalies from last 2000 years. Image description available.
			</image>
			<caption>
				Graph of global average temperature change from year 1 CE to 2019. Image by RCraig09 from an original by Ed Hawkins, <url href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">CC-BY-SA-4.0</url>. <xref ref="fake-news-biblio-climate-change"/> <xref ref="fake-news-image-description-climate-change">Image Description </xref>.
			</caption>
		</figure>
 		<p>
			Along the bottom, we see the years marked off in even increments. On graphs, the bottom line starting on the left and going right is the x-axis. On the left side, the temperature range is indicated. It shows the change in average temperature for each year relative to the temperature in the year 1 CE. That left side line with increments of some important variable is the y-axis. In some cases, the x-axis represents time and the y-axis indicates the degree of some phenomena. In other graphs you might see the x-axis as a causal variable and the y-axis as indicating some outcome. So, in the context of climate change, you might see a graph with the amount of carbon emissions on the x-axis and the average world temperature on the y-axis so the viewer can see how the two are related.
		</p>
		<p>
			But because graphs appear to show objective truth, some people try to abuse that trust people have in graphed data to make things appear differently than they are. As a simple image, such graphs are easily shared online, sometimes with a caption indicating what the viewer is expected to believe as a result. There is a variety of ways to manipulate graphs, we’ll look at two. First, we’ll talk about truncating the y-axis. How wide of a range should you show on the y-axis? What should be the lowest value and what should be the highest? The question is: the y-axis range should go from what to what? In the case of counting things, you might expect the y-axis to range from zero to some plausible number for the most extreme case. But if you wanted to make something look like it was changing more over time you might include a smaller range in the y-axis, which we call truncating the y-axis. 
		</p>
		<p>
			Look at <xref ref="fake-news-misleading-graphs-figure-crime"/>. It shows data from the Uniform Crime Reports from the American F.B.I. <xref ref="fake-news-biblio-fbi"/>. There are plenty of criticism of the accuracy of these data, but setting aside those for a moment, we can use their data to see how to manipulate graphs. I have created a bar graph for the data about the number of murders in the United States in a way that makes it appear that murders went up a lot.
		</p>
		<figure xml:id="fake-news-misleading-graphs-figure-crime">
			<image source="fake-news/images/crime.png">
				A graph in which there are two bars in a bar chart labeled 2018 and 2019 and a y-axis ranging from 16,340 to 16,430. The bar for 2019 looks much higher than the bar for 2018.
			</image>
			<caption>
				Graph of murders in the United States in 2018 and 2019.
			</caption>
		</figure>
		<p>
			But take a look at the y-axis. The lowest number is not zero, it is 16,340 murders in that year. Take a look at the graph in <xref ref="fake-news-misleading-graphs-figure-crime-corrected"/> of the same data. 
		</p>
		<figure xml:id="fake-news-misleading-graphs-figure-crime-corrected">
			<image source="fake-news/images/crime-corrected.png">
 				A graph in which there are two bars in a bar chart labeled 2018 and 2019 and a y-axis ranging from 0 to 18,000. The bar for 2019 looks only slightly higher than the bar for 2018.
 			</image>
 			<caption>
 				A better graph of murders in the United States in 2018 and 2019.
 			</caption>
 		</figure>
 		<p>
			In this graph, the y-axis runs from 0 to 18,000 murders. On this graph, it might even be hard to tell which year had more murders unless you zoomed in or looked at it really closely. To be sure, it is horrible that over 16,000 people were murdered in each of those years. But it seems absurd to argue that there is a big increase in murders when the graph with zero as the lowest point is used.
		</p>
		<p>
			Let’s look at the same problem with a line graph showing change over several years. In this case, we are looking at the number of robberies in the United States over several years. <xref ref="fake-news-misleading-graphs-figure-robberies"/> shows the change over time in the number of Robberies in the United States, again graphed from F.B.I. data <xref ref="fake-news-biblio-fbi"/>.
		</p>
		<figure xml:id="fake-news-misleading-graphs-figure-robberies">
			<image source="fake-news/images/robberies.png">
				A line graph showing robberies in the United States with the years 2014, 2015, and 2016 on the x-axis and the y-axis ranges from 316,000 to 334,000. The line appears to show a rapid increase from 2014 to 2016.
			</image>
			<caption>
				Graph of robberies from 2014 to 2016.
			</caption>
		</figure>
		<p>
			Once again, it looks like robberies were really going up during that time. People seeing this graph might worry that if these trends continue, the streets will not be safe anywhere. They might start thinking about harsher penalties for crimes as possible solutions. But you have probably already noticed the y-axis here. The lowest point is 316,000 robberies, not zero. <xref ref="fake-news-misleading-graphs-figure-robberies-corrected"/> shows the same data graphed with zero robberies as the lowest point.
		</p>
		<figure xml:id="fake-news-misleading-graphs-figure-robberies-corrected">
			<image source="fake-news/images/robberies-corrected.png">
				A line graph showing robberies in the United States with the years 2014, 2015, and 2016 on the x-axis and the y-axis ranges from 0 to 500,000. The line shows a tiny, barely noticeable increase from 2014 to 2016.
			</image>
			<caption>
				A better graph of robberies from 2014 to 2016.
			</caption>
		</figure>
		<p>
			Now it hardly looks like robberies are changing at all. They might have gone up slightly, but it is hardly a massive crime wave happening in 2016 that was not happening in 2014. With the graph in <xref ref="fake-news-misleading-graphs-figure-robberies-corrected"/>, would you want to devote a lot of public resources to stemming the rising tide of robberies? No one wants to be robbed, but it is not exactly a terrifying increase.
		</p>
		<p>
			But some of you may have also started wondering about the x-axis. Where’s the data for 2017, 2018, and 2019? The F.B.I. had data for those years for murders in the last graph, where are they for robberies? That gets to the other side of manipulating graphs. Just like you can shrink the range of the y-axis, you can pick whatever range you want for the x-axis. Sometimes people call that “cherry-picking” the data. You only show the data in a graph that supports an argument you want to make and you exclude the data you want to hide. Once again, we’re looking at shady methods of trying to manipulate people. Take a look at <xref ref="fake-news-misleading-graphs-figure-robberies-corrected-expanded"/>, which shows the same graph as <xref ref="fake-news-misleading-graphs-figure-robberies-corrected"/>, but includes the later years from the report <xref ref="fake-news-biblio-fbi"/>.
		</p>
		<figure xml:id="fake-news-misleading-graphs-figure-robberies-corrected-expanded">
			<image source="fake-news/images/robberies-corrected-expanded.png">
				A line graph showing robberies in the United States with the years 2014 through 2019 on the x-axis and the y-axis ranges from 0 to 500,000. The line shows a tiny, barely noticeable increase from 2014 to 2016 and then a steady decline for each year after that.
			</image>
			<caption>
				A graph of robberies in the US from 2014 to 2019.
			</caption>
		</figure>
		<p>
			Someone who wanted to argue that the United States was becoming an increasingly dangerous place would be more persuasive if they presented <xref ref="fake-news-misleading-graphs-figure-robberies-corrected"/>, than <xref ref="fake-news-misleading-graphs-figure-robberies-corrected-expanded"/>. <xref ref="fake-news-misleading-graphs-figure-robberies-corrected-expanded"/> shows that there is a noticeable drop in robberies in more recent years after the slight uptick for a couple of years. 
		</p>
		<p>
			What counts as an honest graph that is not “fake news”? It is tricky to decide and a lot of it depends on the context. Consider the climate change graph back in <xref ref="fake-news-misleading-graphs-figure-climate"/>. It had a y-axis that ranged from -0.5 C to + 1.0 C. For those of you more accustomed to Fahrenheit rather than Celsius, that’s roughly -1 F to +2 F. You may be thinking, only two degrees hotter? I would barely notice that outside, is this a misleading graph? The thing to keep in mind with this graph is the context. Scientists think that every 0.5 C increase has extremely important impacts on our ability to survive on this planet <xref ref="fake-news-biblio-climate-change-report"/>. Although it might seem like the graph is making a lot out of a little, it is probably a fair graph rather than a misleading one. It is important to consider the context when trying to judge where the y-axis and the x-axis should begin and end. Interpreting numbers always requires critical thinking about what is “a lot” and what is “a little.”
		</p>
	</section>
	<section xml:id="fake-news-solving-for-change">
		<title>Solving for Change</title>
		<p>
			Some of you have been hearing your whole lives that you “shouldn’t believe everything you read on the internet.” But we believe that the skills in this chapter have helped you think through how you decide what to believe and what not to believe. 
		</p>
		<p>
			The section on error analysis focused on how easily small errors can add up to large ones and offered the Five Cs to help you decide how strong evidence is. At the low end of the Five C’s you can see how coincidence and correlation can easily contain errors whereas when you reach consensus, you have such a strong body of evidence from a variety of sources, errors are substantially less likely. So, when you encounter news that makes claims about what the problems are in our society and more importantly, what causes them, you can ask which C they are relying on to make this claim. You can also challenge others who try to argue for a claim with only the low C’s as their support.
		</p>
		<p>
			Then we discussed how to avoid being tricked by misleading graphs in the news. Just because it’s a graph, it does not mean that the most obvious interpretation of the graph is correct. Always think about what a plausible range for the y-axis and the x-axis should be. Think through whether or not the difference shown is truly meaningful. Ask if there is more data in a trend that is not pictured to assess if change is really occurring or if it’s just a random shift over a year or two or among different groups.
		</p>
		<p>
			We hope that these skills will make you a more informed consumer who will not be taken in by fake news either in the mass media or on social media. Just as the 15th century residents of Trent were moved by fake news to commit horrible crimes against their Jewish residents, the story spread throughout Europe and caused further bigotry and violence. The more people with the skills to stop the spread of fake news by refusing to share it and pointing out its flaws, the more likely we are to reach a more socially just world.
		</p>
	</section>
	<reading-questions xml:id="fake-news-reading-questions">
		<exercise>
			Have you ever mistakenly saw a coincidence as evidence for a connection between two events?
		</exercise>
		<exercise>
			Consider a spurious correlation: in the United States, between 2000 and 2009, the number of people who died by becoming tangled in their bedsheets in a year was highly correlated with the amount of cheese consumed that year such that more deaths in a year was associated with more cheese consumption. 
			<figure xml:id="fake-news-image-cheese-bedsheets">
				<image source="fake-news/images/cheese-bedsheets.png">
					Graph showing the correlation between consumption of cheese and the number of people who die by getting tangled in their bedsheets - the graphs look very similar to each other.
				</image>
				<caption>
					Correlation between the consumption of cheese and the number of people who die by getting tangled in their bedsheets. Image <url href="https://creativecommons.org/licenses/by/4.0/">CC-BY-4</url> by Tyler Vigen <xref ref="fake-news-biblio-spurious-correlations"/>.
				</caption>
			</figure>
			Can you think of an explanation for this correlation? Imagine the opposite was found such that the number of people who died from becoming tangled in bedsheets was lower when cheese consumption was higher. Can you come up with an explanation for that result? How easy is it explain any spurious correlation?
		</exercise>
		<exercise>
			Do graphs make a claim seem more likely to be true? Why or why not?
		</exercise>
		<exercise>
			When you see quantitative information used in claims online, what are some things you can look for to indicate that the claim might be misleading? Working as a group, come up with a list of questions that readers should ask about quantitative information they see online.
		</exercise>
	</reading-questions>
	<exercises xml:id="fake-news-exercises">
		<p>
			In addition to the exercises provide here, the Case Studies at the <url href="https://callingbullshit.org/">Calling Bullshit</url> course, hosted by the University of Washington Center for an Informed Public, provide a rich set of fully developed opportunities to explore how quantitative skills can be used to detect "fake news." Instructors are encouraged to explore and use these materials in conjunction with this text.
		</p>
		<p>
			Objective: Understand the sources and consequences of error in a single measurement.
		</p>
		<exercise>
			<p>
				Method: Develop a method to measure the height of your instructor (teacher, professor, etc) and make the measurement. Use that measurement to make another measurement. Then use the second measurement in an equation.
			</p>
			<p>
				Instructions
			</p>
			<ol>
				<li>
					Split up into teams of two or more.
				</li>
				<li>
					One team gets a tape measure. Another team gets a yardstick. Still another team gets a 1-ft ruler.
				</li>
				<li>
					Agree on how you will measure your instructor's height.
				</li>
				<li>
					Make the measurement according to the selected approach.
				</li>
				<li>
					Now measure the length, width, and/or height of the classroom using the instructor's height.
				</li>
				<li>
					Calculate the volume of the classroom using the length, width, and height.
				</li>
				<li>
					Compare the methods selected, the tools available, the individual measurements, and the result from the equation for the different groups.
				</li>
				<li>
					Have each group identify the possible sources of error in the exercise and how they propagate.
				</li>
				<li>
					Discuss the groups' results with respect to the five Cs explained in the text: coincidence, correlation, causation, convergence, and consensus. Which ones apply?
				</li>
				<li>
					Extrapolate the findings to general sources of misinformation, misleading information, studies and research taken in isolation, etc.
				</li>
			</ol>
		</exercise>
		<p>
			Objective: Understand the assumptions which go into a "forecast" or a simulation, in this case an on-line financial calculator, and its purpose.
		</p>
		<exercise>
			<p>
				Method: Study the instructions, narrative, and results for an on-line calculator that forecasts/estimates how you much you will need to save to achieve certain retirement savings goals.
			</p>
			<p>
				Instructions:
			</p>
			<ol>
				<li>
					Thoroughly review the material at this link: https://www.nerdwallet.com/investing/retirement-calculator. Note: there's no need to download the app, just work with this page and see how the numbers change and, importantly, the colors adjust on the graphics
				</li>
				<li>
					Identify as many of the assumptions used to "build" this calculator - some may be obvious, some may not. Hint: A "default" value is also an assumption. There are also hidden assumptions.
				</li>
				<li>
					After reading thoroughly, go through the forms on the left and "play" with the numbers - record the "scenarios" you try by listing and grouping the values you use - age, pre-tax income, current savings, monthly savings rate, etc. You can think of the differences in the "values" you select in the same way as "errors" in the previous example. 
				</li>
				<li>
					See if you can identify the assumption(s) or defaults which have the greatest impact on the results
				</li>
				<li>
					Contemplate why this calculator is available free of charge. What is the purpose of the company making this calculator available? Hint: Where does the "Get started" button take you?
				</li>
				<li>
					Did you remember to hit the link at the very top in very small print, "advertiser disclosure"? And did you click on the "list of partners" at the end of the text box?
				</li>
				<li>
					Discuss and defend whether you would classify this "calculator" as good information, misleading information, or misinformation? Or, is it independent/objective 'content' or advertising? Is it "useful" content regardless of how you classify it? 
				</li>
			</ol>
		</exercise>
		<p>
			Objective: Assess the validity of claims made in a public policy advertisement.
		</p>
		<exercise>
			<p> Colgate toothpaste was once fined for making the misleading claim that "80% of dentists recommend Colgate toothpaste."
			</p>
			<ol>
				<li xml:id="fake-news-exercise-colgate">
					Read about the case that was made against Colgate.  How was their claim true? How was it misleading?
				</li>
				<li>
					How could Colgate have more accurately represented the results of their survey?  Create an advertising statement that uses the same survey information you researched in <xref ref="fake-news-exercise-colgate"/>, but is not misleading.
				</li>
				<li>
					When you hear a claim like Colgate's, why should you be suspicious about it? What particular parts of the claim sound "off"?
				</li>
			</ol>
		</exercise>
		<exercise>
			<p>
				In December 2021, the following meme circulated widely on social media:
			</p>
			<figure xml:id="fake-news-image-polarbear-meme">
				<image source="fake-news/images/polar-bears.png">
					Screenshot of tweet from Patrick Moore (@EcoSenseNow) which says "You should get out more. Polar bears have increased 400% in 45 yrs. Whales are nearly fully recovered. Extinctions are down 90% past century (IUCN). Koalas doing fine. If we could ban wind turbines we could save 85,000 birds of prey/yr in US alone"
				</image>
				<caption>
					December 2021 meme attributed to Patrick Moore (@EcoSenseNow).
				</caption>
			</figure>
			<ol>
				<li>
					Evaluate the 5 claims made in the meme.  Which are true and which are false?
				</li>
				<li>
					What sources did you use to determine whether these claims are true or false? Why are these sources more reliable than the tweet?
				</li>
				<li>
					Which numerical information in the tweet should have served as a clue that some of these claims were not true? Explain why those parts of the claim are a bit suspicious.
				</li>
			</ol>
		</exercise>
		<exercise>
			<p>
				Another meme which circulated on Facebook in July 2021 shows an image of an electric car charging station, along with a claim about the miles per gallon (mpg) that the car charging will get.
			</p>
			<figure xml:id="fake-news-image-car-charger">
				<image source="fake-news/images/diesel-charging-station.png">
					Picture of electric car charging station, with text attributed to Laura Winckel, "This is a picture of a car charging station that are popping up everywhere. This one is in Round Rock Texas.. Here's an interesting fact.... That 350kw generator uses 12 gallons of diesel fuel per hour, and it takes 3 hours to fully charge a car to get 200 miles. That's 36 gallons for 200 miles!!! 5.6 mpg"
				</image>
				<caption>
					Facebook meme which circulated in July 2021, attributed to Laura Winckel.
				</caption>
			</figure>
			<ol>
				<li>
					The meme contains a number of quantitative claims, as well as a non-quantitative claim - that the station is running on a diesel generator, which is not true.  What are the quantitative claims being made?
				</li>
				<li>
					Which of the quantitative claims are true? Cite the sources you used to verify the claims.
				</li>
				<li>
					What about these claims should make you suspicious?
				</li>
			</ol>
		</exercise>
		<exercise>
			<p>
				An <url href="https://www.theguardian.com/sustainable-business/2017/jul/10/100-fossil-fuel-companies-investors-responsible-71-global-emissions-cdp-study-climate-change">article in The Guardian</url> on 07/10/2017 had the provocative headline "Just 100 companies responsible for 71% of global emissions, study says"
			</p>
			<figure xml:id="fake-news-image-guardian-headline">
				<image source="fake-news/images/guardian-headline.png">
					Headline from the Guardian which states "Just 100 companies responsible for 71% of global emissions, study says" and a sub-header "A relatively small number of fossil fuel producers and their investors could hold the key to tackling climate change."
				</image>
				<caption>
					Headline from The Guardian, 07/10/2017.
				</caption>
			</figure>
			<ol>
				<li>
					It is important to learn that a quantitative claim can be true, but still be misleading.  Here, the claim that just 100 companies are responsible for 71% of global emissions is (up to some uncertainty in the exact numbers) factually correct - but it is missing some important context.  Read through the article and do some research on your own.  What do most of the companies listed in this study do? What kinds of products do they produce?
				</li>
				<li>
				 	Based on your research in the previous problem, how is the author using the term "responsible" here? Do you agree that these companies are responsible for 71% of emissions?
				</li>
				<li>
				 	This tweet from April 2021 refers to the claim in the headline:
				 	<figure xml:id="fake-news-image-emissions-bitcoin">
				 		<image source="fake-news/images/emissions-bitcoin.png">
				 			Tweet from April 16, 2021 by @tackyBalrog with the text "71 percent of all emissions are created by the top 100 companies. Normal people buying bitcoin to fight the system aren't the problem."
				 		</image>
				 		<caption>
				 			Tweet from @tackyBalrog on April 16, 2021
				 		</caption>
				 	</figure>
				 	How does this tweet fundamentally misunderstand the claim being made?
				</li>
				<li>
				 	What would be a better way to state the claim being made in the headline? Write your own headline which would present the same quantitative information in a less misleading way.
				</li>
			</ol>
		</exercise>
		<exercise>
			<p>
				Method: Apply "reverse quantitative analysis" (RQA), or working backwards from the numerical result to assess the error, biases, assumptions, uncertainties, exaggerations, dramatization, etc.., to this headline: "Social Isolation Is As Deadly As Smoking Up to 15 Cigarettes a Day," in a public policy/campaign ad by Meals on Wheels (<url href="www.mealsonwheelsamerica.org"/>) to encourage viewers/readers to donate money.
			</p>
			<p>
				Instructions
			</p>
			<ol>
				<li>
					First, from a "math for the people" point of view, what are the most important words in the headline?
				</li>
				<li>
					Research this 'claim" by doing as much searching on the internet as possible and write up your findings. 
				</li>
				<li>
					Ask yourself how do they define "social isolation?" How do they measure it? 
				</li>
				<li>
					Explain to yourself how they have arrived at this association between social isolation and smoking.
				</li>
				<li>
					Apply the 5 Cs to this situation.
				</li>
				<li>
					Would you characterize this statement as good information, misleading information, misinformation, or a flat out lie? Or a worthwhile dramatization, useful exaggeration, or hype? 
				</li>
			</ol>
		</exercise>
		<p>
			Objective: Learn to identify a flawed graph.
		</p>
		<exercise>
			<p>
				The data in the <url href="fake-news/data-files/unemployment-rates.csv">US Unemployment Spreadsheet</url> gives unemployment rates in the United States from the year 2000 to 2023.  Here's a graph of all of the data.
				<figure xml:id="fake-news-image-unemployment">
					<image source="fake-news/images/unemployment.png">
						Line graph showing US Unemployment Rates from 2000 to 2023.
					</image>
					<caption>
						US Unemployment rates from 2000-2023.
					</caption>
				</figure>
				<ol>
					<li>
						Consider the graph in <xref ref="fake-news-image-misleading-unemployment-obama"/>
						<figure xml:id="fake-news-image-misleading-unemployment-obama">
							<image source="fake-news/images/misleading-unemployment-obama.png">
								Line graph showing US Unemployment Rates from November 2008 to January 2010.
							</image>
							<caption>
								US Unemployment Rises during the Obama Administration.
							</caption>
						</figure>
						How is this graph misleading? What do you think that the creator of the graph was trying to prove? How could the graph be made less misleading?
					</li>
					<li>
						Use the data provided in <url href="fake-news/data-files/unemployment-rates.csv">US Unemployment Spreadsheet</url> to create a less misleading graph about the US Unemployment Rate during the Obama administration.
					</li>
					<li>
						Consider the graph in <xref ref="fake-news-image-misleading-unemployment-obama"/>
						<figure xml:id="fake-news-image-misleading-unemployment-trump">
							<image source="fake-news/images/misleading-unemployment-trump.png">
								Bar graph showing the US Unemployment rate in January 2017 and January 2021.
							</image>
							<caption>
								US Unemployment Rises during the Trump Administration.
							</caption>
						</figure>
						How is this graph misleading? What do you think that the creator of the graph was trying to prove? How could the graph be made less misleading?
					</li>
					<li>
						Use the data provided in <url href="fake-news/data-files/unemployment-rates.csv">US Unemployment Spreadsheet</url> to create a less misleading graph about the US Unemployment Rate during the Trump administration.
					</li>
				</ol>
			</p>
		</exercise>
		<exercise>
			<p>
				Use the data provided in <url href="fake-news/data-files/unemployment-rates.csv">US Unemployment Spreadsheet</url> to create a misleading graph.  Choose a statement - true or false - that you would like to convince people of, and use the data to create a graph which would convince someone of that point. Explain why you chose to graph the data the way that you did.
			</p>
		</exercise>
		<exercise>
			<p>
				Method: Find a flawed graph, indicate how the creator of the graph wants people to interpret it, and then discuss how it would be interpreted if the y-axis or x-axis were constructed differently. 
			</p>
			<p>
				Instructions:
			</p>
			<ol>
				<li>
					In a previous class, ask students to bring in graphs they find online. Partisan news organizations are a good place to look.
				</li>
				<li>
					Ask each student to show the class their graph.
				</li>
				<li>
					For each, first ask the students as a whole the likely interpretation intended and then how it could be fixed to cause people to interpret it more accurately. 
				</li>
			</ol>
		</exercise>
	</exercises>
	<section xml:id="fake-news-references">
		<title>References</title>
		<subsection>
			<title>Bibliography</title>
			<biblio xml:id="fake-news-biblio-climate-change">
				RCraig09, E. Hawkins. 2000+ year global temperature including Medieval Warm Period and Little Ice Age - Ed Hawkins.svg. <url href="https://commons.wikimedia.org/wiki/File:2000%2B_year_global_temperature_including_Medieval_Warm_Period_and_Little_Ice_Age_-_Ed_Hawkins.svg"/>
			</biblio>
			<biblio xml:id="fake-news-biblio-fbi">
				Federal Bureau of Information (2021). Federal Bureau of Information Uniform Crime Reporting. Retrieved from <url href="https://www.fbi.gov/services/cjis/ucr"/>.
			</biblio>
			<biblio xml:id="fake-news-biblio-climate-change-report">
				Intergovernmental Panel on Climate Change. (2014). Climate change 2014: Synthesis report. Contribution of working groups I, II and III to the Fifth Assessment Report of the Intergovernmental Panel on Climate Change (Core Writing Team, R. K. Pachauri, &amp; L. A. Meyer, Eds.). Geneva, Switzerland: Author. Retrieved from <url href="https://www.ipcc.ch/report/ar5/syr/"/>.
			</biblio>
			<biblio xml:id="fake-news-biblio-simon-of-trent">
				Kristeller, P. O. (1993). The alleged ritual murder of Simon of Trent (1475) and its literary repercussions: A bibliographic study. Proceedings of the American Academy for Jewish Research, 59, 103-135. <url href="https://doi.org/10.2307/3622714"/>
			</biblio>
			<biblio xml:id="fake-news-biblio-science-of-fake-news">
				Lazer, D. M. J., et al. (2018). The science of fake news: Addressing fake news requires a multidisciplinary effort. Science, 539(6380), 1094-1096. <url href="https://doi.org/10.1126/science.aao2998"/>
			</biblio>
			<biblio xml:id="fake-news-biblio-bls">
				US Bureau of Labor Statistics.  Databases, Tables &amp; Calculators by Subject. <url href="https://data.bls.gov/pdq/SurveyOutputServlet"/>. Visited on 07/26/23.
			</biblio>
			<biblio xml:id="fake-news-biblio-spurious-correlations">
				Tyler Vigen. Spurious Correlations. <url href="https://tylervigen.com/spurious-correlations"/>. Visited on 7/31/23.
			</biblio>
			<biblio xml:id="fake-news-biblio-congressional-budget-office">
				United States Senate Committee on the Budget. <url href="https://www.budget.senate.gov/chairman/newsroom/press/extending-trump-tax-cuts-would-add-46-trillion-to-the-deficit-cbo-finds"/>. Visited on 01/08/2025.
			</biblio>

		</subsection>
		<subsection xml:id="fake-news-image-descriptions">
			<title>Image Descriptions</title>
			<ol>
				<li xml:id="fake-news-image-description-climate-change">
					A graph with the year on the x-axis starting at 1 CE and ending at 2000 CE. The y-axis shows the global average temperature increase for each year relative to the year 1 CE and it ranges from -.05 degrees centigrade to +1.0 degrees centigrade. Around the year 1900, the trend, which had been slowly declining, started rapidly increasing.
				</li>
			</ol>
		</subsection>
	</section>
</chapter>
